{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad57b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Imports + tiny helpers\n",
    "import json, re, time, random, datetime, pathlib, requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def now_utc_iso():\n",
    "    return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
    "\n",
    "def default_headers():\n",
    "    return {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/120.0.0.0 Safari/537.36\"),\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "        \"DNT\": \"1\",\n",
    "    }\n",
    "\n",
    "def batches_root():\n",
    "    return pathlib.Path(\"data/batches\")\n",
    "\n",
    "def latest_batch_path():\n",
    "    root = batches_root()\n",
    "    if not root.exists():\n",
    "        return None\n",
    "    dirs = [p for p in root.iterdir() if p.is_dir()]\n",
    "    return max(dirs, key=lambda p: p.stat().st_mtime) if dirs else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eff7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest batch: 2025-09-23_zips25\n",
      "raw_dir     : C:\\Users\\VICTUS\\Documents\\Rose\\Training\\Fellowship.ai\\real estate listing optimization\\real-estate-listing-optimization\\data\\batches\\2025-09-23_zips25\\raw\n",
      "structured  : C:\\Users\\VICTUS\\Documents\\Rose\\Training\\Fellowship.ai\\real estate listing optimization\\real-estate-listing-optimization\\data\\batches\\2025-09-23_zips25\\structured\n",
      "raw files   : ['0001_meta.json', '0001_raw.html', '0001_response.json']\n",
      "structured  : ['listing_urls.json', 'seed_search_pages.json']\n",
      "listing_urls.json exists? -> True\n"
     ]
    }
   ],
   "source": [
    "# Step 2 — Inspect latest batch; show what's inside raw/structured\n",
    "\n",
    "latest = latest_batch_path()\n",
    "print(\"Latest batch:\", latest.name if latest else \"(none)\")\n",
    "\n",
    "if latest is None:\n",
    "    raise SystemExit(\"No batch found.\\nRun from terminal: `python -m src.batch` then `python -m src.fetch` then `python -m src.extract_search`.\")\n",
    "\n",
    "raw_dir = latest / \"raw\"\n",
    "struct_dir = latest / \"structured\"\n",
    "\n",
    "print(\"raw_dir     :\", raw_dir.resolve())\n",
    "print(\"structured  :\", struct_dir.resolve())\n",
    "\n",
    "print(\"raw files   :\", sorted(p.name for p in raw_dir.glob('*'))[:15])\n",
    "print(\"structured  :\", sorted(p.name for p in struct_dir.glob('*'))[:15])\n",
    "\n",
    "lu_path = struct_dir / \"listing_urls.json\"\n",
    "print(\"listing_urls.json exists? ->\", lu_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea7384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching detail: https://www.redfin.com/TX/Houston/2016-Main-St-77002/unit-1904/home/29503130\n",
      "✅ wrote: 1001_raw.html, 1001_meta.json, 1001_response.json\n",
      "status: 202 | final_url: https://www.redfin.com/TX/Houston/2016-Main-St-77002/unit-1904/home/29503130 | html_len: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 3 — Force-create 1001_raw.html from the first detail URL in listing_urls.json\n",
    "\n",
    "lu = struct_dir / \"listing_urls.json\"\n",
    "if not lu.exists():\n",
    "    raise SystemExit(\"`listing_urls.json` missing.\\nRun: `python -m src.extract_search` after fetching a search page.\")\n",
    "\n",
    "payload = json.loads(lu.read_text(encoding=\"utf-8\"))\n",
    "urls = payload.get(\"urls\", [])\n",
    "if not urls:\n",
    "    raise SystemExit(\"No URLs inside listing_urls.json.\\nMake sure your search page actually had listings.\")\n",
    "\n",
    "first = urls[0]\n",
    "detail_url = first[\"source_url\"] if isinstance(first, dict) else str(first)\n",
    "print(\"Fetching detail:\", detail_url)\n",
    "\n",
    "r = requests.get(detail_url, headers=default_headers(), timeout=30, allow_redirects=True)\n",
    "\n",
    "(raw_dir / \"1001_raw.html\").write_text(r.text or \"\", encoding=\"utf-8\", errors=\"ignore\")\n",
    "(raw_dir / \"1001_response.json\").write_text(\n",
    "    json.dumps({\"status\": r.status_code, \"final_url\": r.url, \"headers\": dict(r.headers)}, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "(raw_dir / \"1001_meta.json\").write_text(\n",
    "    json.dumps({\"requested_url\": detail_url, \"final_url\": r.url, \"status\": r.status_code, \"fetched_at\": now_utc_iso()}, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"✅ wrote: 1001_raw.html, 1001_meta.json, 1001_response.json\")\n",
    "print(\"status:\", r.status_code, \"| final_url:\", r.url, \"| html_len:\", len(r.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c684ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote structured: data\\batches\\2025-09-23_zips25\\structured\\1001.json\n",
      "{'beds': None, 'baths': None, 'interior_area_sqft': None} price: None\n"
     ]
    }
   ],
   "source": [
    "# Step 4 — Parse 1001_raw.html into a structured JSON (core fields only)\n",
    "\n",
    "html = (raw_dir / \"1001_raw.html\").read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "meta = json.loads((raw_dir / \"1001_meta.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "source_url = (meta.get(\"final_url\") or meta.get(\"requested_url\") or \"\").lower()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "def safe_float(x):\n",
    "    if x is None: return None\n",
    "    if isinstance(x, (int,float)): return float(x)\n",
    "    s = re.sub(r\"[^\\d\\.]\", \"\", str(x))\n",
    "    try: return float(s) if s else None\n",
    "    except: return None\n",
    "\n",
    "def to_int(x):\n",
    "    v = safe_float(x)\n",
    "    return int(v) if v is not None else None\n",
    "\n",
    "# 1) schema.org JSON-LD\n",
    "rec = {\"price\":None,\"beds\":None,\"baths\":None,\"sqft\":None,\"year\":None,\n",
    "       \"addr\":{\"street\":None,\"unit\":None,\"city\":None,\"state\":None,\"postal_code\":None}, \"photos\":[]}\n",
    "\n",
    "for sc in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "    try:\n",
    "        data = json.loads(sc.string or \"{}\")\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    def walk(n):\n",
    "        if isinstance(n, dict):\n",
    "            t = str(n.get(\"@type\") or n.get(\"type\") or \"\").lower()\n",
    "            if any(x in t for x in [\"residence\",\"singlefamily\",\"house\",\"apartment\",\"offer\",\"realestatelisting\"]):\n",
    "                offer = n.get(\"offers\") or {}\n",
    "                if isinstance(offer, dict):\n",
    "                    rec[\"price\"] = rec[\"price\"] or safe_float(offer.get(\"price\") or offer.get(\"lowPrice\") or offer.get(\"highPrice\"))\n",
    "                addr = n.get(\"address\") or {}\n",
    "                if isinstance(addr, dict):\n",
    "                    rec[\"addr\"].update({\n",
    "                        \"street\": addr.get(\"streetAddress\", rec[\"addr\"][\"street\"]),\n",
    "                        \"city\": addr.get(\"addressLocality\", rec[\"addr\"][\"city\"]),\n",
    "                        \"state\": addr.get(\"addressRegion\", rec[\"addr\"][\"state\"]),\n",
    "                        \"postal_code\": addr.get(\"postalCode\", rec[\"addr\"][\"postal_code\"]),\n",
    "                    })\n",
    "                rec[\"beds\"]  = rec[\"beds\"]  or safe_float(n.get(\"numberOfRooms\") or n.get(\"bedrooms\"))\n",
    "                rec[\"baths\"] = rec[\"baths\"] or safe_float(n.get(\"bathroomCount\") or n.get(\"bathrooms\"))\n",
    "                area = n.get(\"floorSize\") or {}\n",
    "                if isinstance(area, dict):\n",
    "                    rec[\"sqft\"] = rec[\"sqft\"] or to_int(area.get(\"value\"))\n",
    "                imgs = n.get(\"image\")\n",
    "                if isinstance(imgs, list):\n",
    "                    rec[\"photos\"].extend([u for u in imgs if isinstance(u, str)])\n",
    "                elif isinstance(imgs, str):\n",
    "                    rec[\"photos\"].append(imgs)\n",
    "            for v in n.values(): walk(v)\n",
    "        elif isinstance(n, list):\n",
    "            for v in n: walk(v)\n",
    "    walk(data)\n",
    "\n",
    "rec[\"photos\"] = list(dict.fromkeys(rec[\"photos\"]))[:50]\n",
    "\n",
    "# 2) regex fallbacks (if missing)\n",
    "if rec[\"sqft\"] is None:\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(sq\\s*ft|sqft)', html, re.I)\n",
    "    if m:\n",
    "        try: rec[\"sqft\"] = int(float(m.group(1).replace(\",\", \"\")))\n",
    "        except: pass\n",
    "\n",
    "if rec[\"price\"] is None:\n",
    "    m = re.search(r'Price[:\\s]*\\$?\\s*([\\d,\\,\\.]+)', html, re.I)\n",
    "    if m:\n",
    "        try: rec[\"price\"] = float(m.group(1).replace(\",\", \"\"))\n",
    "        except: pass\n",
    "\n",
    "# Build structured object (MVP fields)\n",
    "structured = {\n",
    "    \"listing_id\": None,\n",
    "    \"platform_id\": (\"redfin\" if \"redfin.com\" in source_url else \"zillow\" if \"zillow.com\" in source_url else \"other\"),\n",
    "    \"source_url\": source_url,\n",
    "    \"external_property_id\": None,  # kept None in quick parser\n",
    "    \"batch_id\": latest.name,\n",
    "    \"scraped_timestamp\": now_utc_iso(),\n",
    "\n",
    "    \"address\": {\n",
    "        \"street\": rec[\"addr\"][\"street\"],\n",
    "        \"unit\": rec[\"addr\"][\"unit\"],\n",
    "        \"city\": rec[\"addr\"][\"city\"],\n",
    "        \"state\": rec[\"addr\"][\"state\"],\n",
    "        \"postal_code\": rec[\"addr\"][\"postal_code\"],\n",
    "    },\n",
    "    \"latitude\": None,\n",
    "    \"longitude\": None,\n",
    "\n",
    "    \"property_type\": None,\n",
    "    \"property_subtype\": None,\n",
    "    \"beds\": rec[\"beds\"],\n",
    "    \"baths\": rec[\"baths\"],\n",
    "    \"interior_area_sqft\": rec[\"sqft\"],\n",
    "    \"lot_sqft\": None,\n",
    "    \"year_built\": rec[\"year\"],\n",
    "    \"condition\": None,\n",
    "\n",
    "    \"listing\": {\n",
    "        \"listing_type\": \"sell\",\n",
    "        \"status\": None,\n",
    "        \"list_date\": None,\n",
    "        \"days_on_market\": None,\n",
    "        \"list_price\": rec[\"price\"],\n",
    "        \"price_per_sqft\": round(rec[\"price\"]/rec[\"sqft\"], 2) if rec[\"price\"] and rec[\"sqft\"] else None\n",
    "    },\n",
    "\n",
    "    \"description\": None,\n",
    "    \"media\": [{\"url\": u, \"type\": \"image\", \"caption\": None} for u in rec[\"photos\"]],\n",
    "    \"features\": {},\n",
    "    \"market_signals\": {\"views\": None, \"saves\": None, \"share_count\": None},\n",
    "    \"similar_properties\": [],\n",
    "    \"possible_duplicate\": False,\n",
    "    \"duplicate_candidates\": []\n",
    "}\n",
    "\n",
    "out = (struct_dir / \"1001.json\")\n",
    "out.write_text(json.dumps(structured, indent=2), encoding=\"utf-8\")\n",
    "print(\"✅ Wrote structured:\", out)\n",
    "print({k: structured[k] for k in [\"beds\",\"baths\",\"interior_area_sqft\"]}, \"price:\", structured[\"listing\"][\"list_price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2023f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched 1001: 202\n",
      "fetched 1002: 202\n",
      "fetched 1003: 202\n",
      "fetched 1004: 202\n",
      "✅ wrote structured: [1001, 1002, 1003, 1004]\n"
     ]
    }
   ],
   "source": [
    "# Step 5 — (Optional) Fetch 4 detail pages & parse them all\n",
    "\n",
    "# 5.a) load first 4 detail URLs\n",
    "lu = json.loads((struct_dir / \"listing_urls.json\").read_text(encoding=\"utf-8\"))\n",
    "detail_urls = [row[\"source_url\"] if isinstance(row, dict) else str(row) for row in lu[\"urls\"][:4]]\n",
    "\n",
    "# 5.b) fetch details 1001..1004\n",
    "for i, u in enumerate(detail_urls, start=1001):\n",
    "    r = requests.get(u, headers=default_headers(), timeout=30, allow_redirects=True)\n",
    "    (raw_dir / f\"{i:04d}_raw.html\").write_text(r.text or \"\", encoding=\"utf-8\", errors=\"ignore\")\n",
    "    (raw_dir / f\"{i:04d}_meta.json\").write_text(json.dumps({\"requested_url\": u, \"final_url\": r.url, \"status\": r.status_code, \"fetched_at\": now_utc_iso()}, indent=2), encoding=\"utf-8\")\n",
    "    (raw_dir / f\"{i:04d}_response.json\").write_text(json.dumps({\"status\": r.status_code, \"final_url\": r.url, \"headers\": dict(r.headers)}, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"fetched {i}: {r.status_code}\")\n",
    "    time.sleep(random.uniform(1.2, 2.8))\n",
    "\n",
    "# 5.c) parse details (using the same quick parser as step 4)\n",
    "def quick_parse(idx: int):\n",
    "    html = (raw_dir / f\"{idx:04d}_raw.html\").read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    meta = json.loads((raw_dir / f\"{idx:04d}_meta.json\").read_text(encoding=\"utf-8\"))\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # reuse the minimal logic from Step 4:\n",
    "    # (for brevity, call the same block by importing globals we already defined)\n",
    "    # here we'll just write a small shortcut: copy beds/baths/price/sqft regex fallbacks only\n",
    "    price = None; beds=None; baths=None; sqft=None\n",
    "    m = re.search(r'\\$[\\s]*([\\d,]+)', html); \n",
    "    price = float(m.group(1).replace(\",\", \"\")) if m else None\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*beds?', html, re.I); beds = float(m.group(1)) if m else None\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*baths?', html, re.I); baths = float(m.group(1)) if m else None\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(sq\\s*ft|sqft)', html, re.I); sqft = int(float(m.group(1).replace(\",\", \"\"))) if m else None\n",
    "    data = {\n",
    "        \"listing_id\": None,\n",
    "        \"platform_id\": (\"redfin\" if \"redfin.com\" in (meta.get(\"final_url\",\"\").lower()) else \"zillow\" if \"zillow.com\" in (meta.get(\"final_url\",\"\").lower()) else \"other\"),\n",
    "        \"source_url\": (meta.get(\"final_url\") or meta.get(\"requested_url\") or \"\").lower(),\n",
    "        \"external_property_id\": None,\n",
    "        \"batch_id\": latest.name,\n",
    "        \"scraped_timestamp\": now_utc_iso(),\n",
    "        \"address\": {\"street\": None, \"unit\": None, \"city\": None, \"state\": None, \"postal_code\": None},\n",
    "        \"latitude\": None, \"longitude\": None,\n",
    "        \"property_type\": None, \"property_subtype\": None,\n",
    "        \"beds\": beds, \"baths\": baths, \"interior_area_sqft\": sqft, \"lot_sqft\": None, \"year_built\": None, \"condition\": None,\n",
    "        \"listing\": {\"listing_type\": \"sell\", \"status\": None, \"list_date\": None, \"days_on_market\": None,\n",
    "                    \"list_price\": price, \"price_per_sqft\": round(price/sqft,2) if price and sqft else None},\n",
    "        \"description\": None, \"media\": [], \"features\": {}, \"market_signals\": {\"views\": None, \"saves\": None, \"share_count\": None},\n",
    "        \"similar_properties\": [], \"possible_duplicate\": False, \"duplicate_candidates\": []\n",
    "    }\n",
    "    (struct_dir / f\"{idx:04d}.json\").write_text(json.dumps(data, indent=2), encoding=\"utf-8\")\n",
    "    return idx\n",
    "\n",
    "out_idxs = [quick_parse(i) for i in range(1001, 1005)]\n",
    "print(\"✅ wrote structured:\", out_idxs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
